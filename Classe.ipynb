{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "657f5a27-bb25-44c4-920e-1a80cab199c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyiris.ingestion.config.file_system_config import FileSystemConfig\n",
    "from pyiris.ingestion.extract import ExtractService, FileReader\n",
    "from pyiris.ingestion.load import LoadService, FileWriter\n",
    "from pyiris.infrastructure import Spark\n",
    "\n",
    "import pyspark.sql.functions as f \n",
    "from pyspark.sql import  Row, Window\n",
    "\n",
    "import pyspark as ps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV,cross_validate\n",
    "from scipy.stats import uniform, randint, loguniform #,quniform\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error,make_scorer,mean_absolute_error, mean_squared_error,r2_score\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "# from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler,LabelEncoder\n",
    "from sklearn.base import clone\n",
    "\n",
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, hp, SparkTrials, STATUS_OK, Trials\n",
    " \n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "# import pymer4\n",
    "# from pymer4.models import Lmer\n",
    "\n",
    "from datetime import datetime\n",
    "import os, sys\n",
    "import json\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from scipy.special import gammaln  # for Poisson and Gamma likelihoods\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.ERROR)\n",
    "pyiris_spark = Spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c54140b-7a4d-4418-a17d-f2a702ac2154",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d100f25d-33a9-46ff-99a1-45e744fd69eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class GLMM:\n",
    "    def __init__(self, X=None, y=None, trials=None, groups=None, distribution='gaussian', link='identity',\n",
    "                random_effect_cols=None, formula=None, data=None, regularization=None, reg_lambda=0.0):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - Either provide X (n x p numpy array or DataFrame), y (n,), groups, and random_effect_cols\n",
    "        OR supply a formula (R-style string) and a pandas DataFrame (data).\n",
    "        - distribution: one of 'gaussian', 'binomial', 'gamma', 'poisson'\n",
    "        - link: one of 'identity', 'log', 'logit'\n",
    "        - trials: number of trials for each binomial observation (only needed for binomial)\n",
    "        - groups: dict mapping group name -> group values (if not using formula)\n",
    "        - random_effect_cols: dict mapping group name -> list of indices in X (if not using formula)\n",
    "        - formula: R-style formula with support for multiple grouping variables\n",
    "        - data: pandas DataFrame (required if formula is provided)\n",
    "        - regularization: None, 'L1', or 'L2'\n",
    "        - reg_lambda: regularization coefficient (nonnegative float)\n",
    "        \"\"\"\n",
    "        self.distribution = distribution.lower()\n",
    "        self.link = link.lower()\n",
    "        self.regularization = regularization\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.formula = formula\n",
    "        self.cat_encodings = {}  # Will store categorical variable encodings\n",
    "        \n",
    "        if formula is not None and data is not None:\n",
    "            # Use our formula parser\n",
    "            self.formula = formula\n",
    "            X, y, trials, groups, group_vars, random_effect_cols, fixed_colnames = self.parse_formula(formula, data)\n",
    "            self.fixed_colnames = fixed_colnames\n",
    "            self.group_vars = group_vars\n",
    "            self.trials = torch.tensor(trials, dtype=torch.float32).view(-1, 1) if trials is not None else None\n",
    "        else:\n",
    "            if X is None or y is None or groups is None:\n",
    "                raise ValueError(\"Either supply (X, y, groups, random_effect_cols) or (formula and data)\")\n",
    "            # If X is provided as a DataFrame, get its column names\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                self.fixed_colnames = list(X.columns)\n",
    "                X = X.values\n",
    "            else:\n",
    "                # If X is a numpy array, we assume columns are numbered\n",
    "                self.fixed_colnames = [f\"X{i}\" for i in range(X.shape[1])]\n",
    "            \n",
    "            # In this case, we need to update the group handling\n",
    "            if not isinstance(groups, dict):\n",
    "                # Convert to dict format if provided as single group\n",
    "                if random_effect_cols is None:\n",
    "                    random_effect_cols = {'Group': [0]}  # Default to random intercept\n",
    "                else:\n",
    "                    random_effect_cols = {'Group': random_effect_cols}\n",
    "                groups = {'Group': groups}\n",
    "            \n",
    "            self.group_vars = list(groups.keys())\n",
    "                \n",
    "            # For binomial with trials\n",
    "            if self.distribution == 'binomial' and trials is not None:\n",
    "                self.trials = torch.tensor(trials, dtype=torch.float32).view(-1, 1)\n",
    "            else:\n",
    "                self.trials = None\n",
    "        \n",
    "        # Store fixed effects design matrix and response\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "        self.n, self.p = self.X.shape\n",
    "        \n",
    "        # Process multiple groups\n",
    "        self.groups = groups\n",
    "        self.group_data = {}  # Will store processed group data\n",
    "        \n",
    "        # Initialize parameters for each group\n",
    "        self.random_effect_cols = random_effect_cols\n",
    "        self.beta = nn.Parameter(torch.zeros(self.p, 1, dtype=torch.float32))\n",
    "        \n",
    "        # Create random effects parameters for each group\n",
    "        self.b = {}  # Dict mapping group name -> random effects parameter\n",
    "        self.log_sigma_b = {}  # Dict mapping group name -> log std dev parameter\n",
    "        \n",
    "        for group_var in self.group_vars:\n",
    "            group_values = np.array(groups[group_var])\n",
    "            unique_groups, group_idx = np.unique(group_values, return_inverse=True)\n",
    "            \n",
    "            self.group_data[group_var] = {\n",
    "                'group_idx': torch.tensor(group_idx, dtype=torch.long),\n",
    "                'n_groups': len(unique_groups),\n",
    "                'unique_groups': unique_groups\n",
    "            }\n",
    "            \n",
    "            # Get random effect columns for this grouping variable\n",
    "            group_re_cols = random_effect_cols[group_var]\n",
    "            d = len(group_re_cols)\n",
    "            \n",
    "            # Build random effect design matrix Z for this group\n",
    "            Z = np.zeros((self.n, d))\n",
    "            for j, col_idx in enumerate(group_re_cols):\n",
    "                # For random intercept (or any other column), use the corresponding X column\n",
    "                Z[:, j] = self.X[:, col_idx].detach().numpy().ravel()\n",
    "            \n",
    "            self.group_data[group_var]['Z'] = torch.tensor(Z, dtype=torch.float32)\n",
    "            self.group_data[group_var]['d'] = d\n",
    "            self.group_data[group_var]['random_effect_cols'] = group_re_cols\n",
    "            \n",
    "            # Initialize random effects b for this group (n_groups x d)\n",
    "            self.b[group_var] = nn.Parameter(torch.zeros(len(unique_groups), d, dtype=torch.float32))\n",
    "            # Initialize log std dev of random effects for this group (d-dimensional vector)\n",
    "            self.log_sigma_b[group_var] = nn.Parameter(torch.zeros(d, dtype=torch.float32))\n",
    "        \n",
    "        # For gaussian, also estimate residual sigma_y; for gamma, estimate shape phi\n",
    "        if self.distribution == 'gaussian':\n",
    "            self.log_sigma_y = nn.Parameter(torch.tensor(0.0, dtype=torch.float32))\n",
    "        elif self.distribution == 'gamma':\n",
    "            self.log_phi = nn.Parameter(torch.tensor(0.0, dtype=torch.float32))\n",
    "            \n",
    "        # Collect parameters to optimize\n",
    "        self.params = [self.beta]\n",
    "        for group_var in self.group_vars:\n",
    "            self.params.append(self.b[group_var])\n",
    "            self.params.append(self.log_sigma_b[group_var])\n",
    "        \n",
    "        if self.distribution == 'gaussian':\n",
    "            self.params.append(self.log_sigma_y)\n",
    "        elif self.distribution == 'gamma':\n",
    "            self.params.append(self.log_phi)\n",
    "            \n",
    "        self.loss_history = []\n",
    "\n",
    "    def inverse_link(self, eta, link):\n",
    "        \"\"\"Helper: Inverse Link Functions\"\"\"\n",
    "        if link == 'identity':\n",
    "            return eta\n",
    "        elif link == 'log':\n",
    "            return torch.exp(eta)\n",
    "        elif link == 'logit':\n",
    "            return torch.sigmoid(eta)\n",
    "        else:\n",
    "            raise ValueError(\"Link not recognized.\")\n",
    "\n",
    "    def loglik_gaussian(self, y, mu, sigma_y):\n",
    "        \"\"\"Helper: Log-likelihood function for Gaussian distribution\"\"\"\n",
    "        ll = -0.5 * torch.log(2 * math.pi * sigma_y**2) - 0.5 * ((y - mu)**2) / (sigma_y**2)\n",
    "        return ll\n",
    "\n",
    "    def loglik_binomial(self, y, mu, trials=None):\n",
    "        \"\"\"Helper: Log-likelihood function for Binomial distribution\n",
    "        \n",
    "        Args:\n",
    "            y: Success counts\n",
    "            mu: Probability of success\n",
    "            trials: Number of trials (if None, assumes binary trials)\n",
    "        \"\"\"\n",
    "        eps = 1e-6\n",
    "        mu = torch.clamp(mu, eps, 1 - eps)\n",
    "        \n",
    "        if trials is not None:\n",
    "            # Binomial distribution with multiple trials\n",
    "            failures = trials - y\n",
    "            ll = y * torch.log(mu) + failures * torch.log(1 - mu)\n",
    "            # Add binomial coefficient terms\n",
    "            # Note: We omit the binomial coefficient as it's a constant w.r.t parameters\n",
    "        else:\n",
    "            # Binary case (Bernoulli)\n",
    "            ll = y * torch.log(mu) + (1 - y) * torch.log(1 - mu)\n",
    "            \n",
    "        return ll\n",
    "\n",
    "    def loglik_poisson(self, y, mu):\n",
    "        \"\"\"Helper: Log-likelihood function for Poisson distribution\"\"\"\n",
    "        ll = -mu + y * torch.log(mu) - torch.lgamma(y + 1)\n",
    "        return ll\n",
    "\n",
    "    def loglik_gamma(self, y, mu, phi):\n",
    "        \"\"\"Helper: Log-likelihood function for Gamma distribution\"\"\"\n",
    "        # Parameterization: E(y)=mu, shape=phi.\n",
    "        eps = 1e-6\n",
    "        mu = torch.clamp(mu, eps, None)\n",
    "        ll = (phi * torch.log(phi/mu) - torch.lgamma(phi)) + (phi - 1)*torch.log(y) - (phi*y/mu)\n",
    "        return ll\n",
    "\n",
    "    def parse_formula(self, formula, data):\n",
    "        \"\"\"\n",
    "        Parse an R-style formula with enhanced support for:\n",
    "        - Multiple random effects terms with different grouping variables\n",
    "        - Automatic detection and encoding of categorical variables\n",
    "        \n",
    "        Expected forms: \n",
    "        - \"y ~ x1 + x2 + (1 + x2 | group1) + (1 | group2)\"\n",
    "        - \"cbind(win, loss) ~ x1 + x2 + (1 | group)\" for binomial with trial size > 1\n",
    "        \n",
    "        Returns:\n",
    "        X: fixed effects design matrix as numpy array (including intercept)\n",
    "        y: response vector (numpy array)\n",
    "        trials: total number of trials for binomial (numpy array or None)\n",
    "        groups: grouping variables (dict mapping group name -> numpy array)\n",
    "        group_vars: list of grouping variable names\n",
    "        random_effect_cols: dict mapping group name -> list of indices in X for random slopes\n",
    "        fixed_colnames: list of column names in X\n",
    "        \"\"\"\n",
    "        import re\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        \n",
    "        # Split formula at '~'\n",
    "        lhs, rhs = formula.split(\"~\")\n",
    "        lhs = lhs.strip()\n",
    "        rhs = rhs.strip()\n",
    "        \n",
    "        # Parse response variable\n",
    "        trials = None\n",
    "        if lhs.startswith(\"cbind(\") and lhs.endswith(\")\"):\n",
    "            # Extract success and failure counts for binomial\n",
    "            inner = lhs[6:-1]  # Remove cbind( and )\n",
    "            success_var, failure_var = [s.strip() for s in inner.split(\",\")]\n",
    "            \n",
    "            # Extract success and failure counts from data\n",
    "            successes = data[success_var].values\n",
    "            failures = data[failure_var].values\n",
    "            \n",
    "            # Calculate total trials and response (proportion of successes)\n",
    "            trials = successes + failures\n",
    "            y = successes\n",
    "            \n",
    "            # Set distribution to binomial if not already set\n",
    "            if self.distribution != 'binomial':\n",
    "                print(f\"Warning: Changing distribution from '{self.distribution}' to 'binomial' based on formula.\")\n",
    "                self.distribution = 'binomial'\n",
    "                \n",
    "            # Default to logit link for binomial if not specified\n",
    "            if self.link == 'identity':\n",
    "                print(\"Warning: Changing link from 'identity' to 'logit' for binomial model.\")\n",
    "                self.link = 'logit'\n",
    "        else:\n",
    "            # Standard single response variable\n",
    "            response = lhs\n",
    "            y = data[response].values\n",
    "        \n",
    "        # Find all random effect terms: patterns like \"( ... | ... )\"\n",
    "        rand_terms = []\n",
    "        rand_pattern = r\"\\((.*?)\\s*\\|\\s*(.*?)\\)\"\n",
    "        \n",
    "        # Extract all random effect terms\n",
    "        for match in re.finditer(rand_pattern, rhs):\n",
    "            rand_predictors = match.group(1).strip()  # e.g., \"1 + x2\"\n",
    "            group_var = match.group(2).strip()        # e.g., \"group\"\n",
    "            rand_terms.append((rand_predictors, group_var))\n",
    "        \n",
    "        # Remove all random terms from rhs\n",
    "        fixed_part = re.sub(r\"\\(.*?\\)\", \"\", rhs)\n",
    "        \n",
    "        # Fixed effects: split remaining rhs by '+' and remove any empty parts\n",
    "        fixed_terms = [term.strip() for term in fixed_part.split(\"+\") if term.strip() and term.strip() != \"-1\"]\n",
    "        \n",
    "        # Always include an intercept if not explicitly removed\n",
    "        include_intercept = not ((\"-1\" in fixed_part) or (\"- 1\" in fixed_part))\n",
    "        \n",
    "        # Identify categorical variables in fixed terms\n",
    "        categorical_vars = []\n",
    "        numerical_vars = []\n",
    "        \n",
    "        for term in fixed_terms:\n",
    "            if term in data.columns:\n",
    "                # Check if variable is categorical or should be treated as such\n",
    "                if pd.api.types.is_categorical_dtype(data[term]) or pd.api.types.is_object_dtype(data[term]):\n",
    "                    categorical_vars.append(term)\n",
    "                else:\n",
    "                    numerical_vars.append(term)\n",
    "        \n",
    "        # Create dummy variables for categorical variables\n",
    "        X_dummies_dict = {}\n",
    "        cat_encodings = {}  # Store encodings for prediction\n",
    "        \n",
    "        for cat_var in categorical_vars:\n",
    "            # Get dummies, drop first category to avoid collinearity\n",
    "            dummies = pd.get_dummies(data[cat_var], prefix=cat_var, drop_first=True)\n",
    "            X_dummies_dict[cat_var] = dummies\n",
    "            \n",
    "            # Store encoding information for future prediction\n",
    "            categories = data[cat_var].unique()\n",
    "            cat_encodings[cat_var] = {\n",
    "                'categories': categories,\n",
    "                'dummy_cols': dummies.columns.tolist()\n",
    "            }\n",
    "        \n",
    "        # Store the categorical encodings as a class attribute\n",
    "        self.cat_encodings = cat_encodings\n",
    "        \n",
    "        # Build fixed effects design matrix X\n",
    "        n = data.shape[0]\n",
    "        X_parts = []\n",
    "        \n",
    "        # Start with intercept if needed\n",
    "        if include_intercept:\n",
    "            X_parts.append(np.ones((n, 1)))\n",
    "            fixed_colnames = [\"Intercept\"]\n",
    "        else:\n",
    "            fixed_colnames = []\n",
    "        \n",
    "        # Add numerical variables\n",
    "        if numerical_vars:\n",
    "            X_num = data[numerical_vars].values\n",
    "            X_parts.append(X_num)\n",
    "            fixed_colnames.extend(numerical_vars)\n",
    "        \n",
    "        # Add categorical dummy variables\n",
    "        for cat_var in categorical_vars:\n",
    "            dummies = X_dummies_dict[cat_var]\n",
    "            X_parts.append(dummies.values)\n",
    "            fixed_colnames.extend(dummies.columns.tolist())\n",
    "        \n",
    "        # Combine all parts into the design matrix\n",
    "        if X_parts:\n",
    "            X = np.hstack(X_parts)\n",
    "        else:\n",
    "            # Fallback to just intercept if no predictors\n",
    "            X = np.ones((n, 1))\n",
    "            fixed_colnames = [\"Intercept\"]\n",
    "        \n",
    "        # Process random effects terms\n",
    "        groups = {}  # Dict mapping group var name to group values array\n",
    "        random_effect_cols = {}  # Dict mapping group var name to list of indices\n",
    "        group_vars = []  # List of group variable names\n",
    "        \n",
    "        for rand_pred, group_var in rand_terms:\n",
    "            group_vars.append(group_var)\n",
    "            groups[group_var] = data[group_var].values\n",
    "            \n",
    "            # Split rand_predictors by '+'\n",
    "            tokens = [tok.strip() for tok in rand_pred.split(\"+\") if tok.strip()]\n",
    "            # For each token, map to an index in fixed_colnames\n",
    "            group_cols = []\n",
    "            \n",
    "            for tok in tokens:\n",
    "                if tok == \"1\" and \"Intercept\" in fixed_colnames:\n",
    "                    # Random intercept corresponds to intercept column index\n",
    "                    intercept_idx = fixed_colnames.index(\"Intercept\")\n",
    "                    group_cols.append(intercept_idx)\n",
    "                elif tok in fixed_colnames:\n",
    "                    idx = fixed_colnames.index(tok)\n",
    "                    group_cols.append(idx)\n",
    "                elif tok in categorical_vars:\n",
    "                    # Handle categorical variables - all dummy columns should be included\n",
    "                    for dummy_col in cat_encodings[tok]['dummy_cols']:\n",
    "                        if dummy_col in fixed_colnames:\n",
    "                            idx = fixed_colnames.index(dummy_col)\n",
    "                            group_cols.append(idx)\n",
    "                else:\n",
    "                    # Check if token is a dummy variable from categorical variable\n",
    "                    for cat_var, encoding in cat_encodings.items():\n",
    "                        if tok in encoding['dummy_cols']:\n",
    "                            idx = fixed_colnames.index(tok)\n",
    "                            group_cols.append(idx)\n",
    "                            break\n",
    "                    else:\n",
    "                        raise ValueError(f\"Random effect term '{tok}' not found among fixed effects: {fixed_colnames}\")\n",
    "            \n",
    "            random_effect_cols[group_var] = group_cols\n",
    "        \n",
    "        if not group_vars:\n",
    "            # If no random term found\n",
    "            raise ValueError(\"No random effects term found in the formula. Please include at least one random term using (term|group).\")\n",
    "        \n",
    "        return X, y, trials, groups, group_vars, random_effect_cols, fixed_colnames\n",
    "\n",
    "    def model_loglik(self):\n",
    "        \"\"\"\n",
    "        Compute the negative joint log-likelihood with support for multiple grouping variables:\n",
    "        - observation log-likelihood based on distribution and link\n",
    "        - penalty for random effects assuming b_g ~ N(0, diag(sigma_b^2))\n",
    "        - plus optional regularization penalty on beta and b\n",
    "        \"\"\"\n",
    "        # Initialize linear predictor with fixed effects\n",
    "        eta = self.X @ self.beta\n",
    "        \n",
    "        # Add random effects contribution from each grouping variable\n",
    "        for group_var in self.group_vars:\n",
    "            group_data = self.group_data[group_var]\n",
    "            Z = group_data['Z']\n",
    "            group_idx = group_data['group_idx']\n",
    "            \n",
    "            # Get random effects for this group's observations\n",
    "            b_obs = self.b[group_var][group_idx]  # shape (n, d)\n",
    "            \n",
    "            # Add contribution from this grouping variable's random effects\n",
    "            rand_part = torch.sum(Z * b_obs, dim=1, keepdim=True)\n",
    "            eta = eta + rand_part\n",
    "        \n",
    "        # Apply link function\n",
    "        mu = self.inverse_link(eta, self.link)\n",
    "        \n",
    "        # Compute observation likelihood based on distribution\n",
    "        if self.distribution == 'gaussian':\n",
    "            sigma_y = torch.exp(self.log_sigma_y)\n",
    "            ll_obs = self.loglik_gaussian(self.y, mu, sigma_y)\n",
    "        elif self.distribution == 'binomial':\n",
    "            ll_obs = self.loglik_binomial(self.y, mu, self.trials)\n",
    "        elif self.distribution == 'poisson':\n",
    "            ll_obs = self.loglik_poisson(self.y, mu)\n",
    "        elif self.distribution == 'gamma':\n",
    "            phi = torch.exp(self.log_phi)\n",
    "            ll_obs = self.loglik_gamma(self.y, mu, phi)\n",
    "        else:\n",
    "            raise ValueError(\"Distribution not recognized.\")\n",
    "        \n",
    "        ll_obs_sum = torch.sum(ll_obs)\n",
    "        \n",
    "        # Random effects penalty for each grouping variable\n",
    "        ll_rand = 0.0\n",
    "        for group_var in self.group_vars:\n",
    "            group_data = self.group_data[group_var]\n",
    "            n_groups = group_data['n_groups']\n",
    "            d = group_data['d']\n",
    "            \n",
    "            # Get sigma_b for this group\n",
    "            sigma_b = torch.exp(self.log_sigma_b[group_var])  # shape (d,)\n",
    "            \n",
    "            # Add penalty: each b_{g,j} ~ N(0, sigma_b[j]^2)\n",
    "            ll_rand += -0.5 * torch.sum((self.b[group_var]**2) / (sigma_b**2)) \\\n",
    "                    - n_groups * torch.sum(torch.log(sigma_b)) \\\n",
    "                    - 0.5 * n_groups * d * math.log(2 * math.pi)\n",
    "        \n",
    "        total_ll = ll_obs_sum + ll_rand\n",
    "        \n",
    "        # Regularization penalty (if any) on fixed effects and random effects\n",
    "        reg_penalty = 0.0\n",
    "        if self.regularization is not None and self.reg_lambda > 0:\n",
    "            if self.regularization.lower() == 'l1':\n",
    "                reg_penalty = self.reg_lambda * torch.sum(torch.abs(self.beta))\n",
    "                for group_var in self.group_vars:\n",
    "                    reg_penalty += self.reg_lambda * torch.sum(torch.abs(self.b[group_var]))\n",
    "            elif self.regularization.lower() == 'l2':\n",
    "                reg_penalty = self.reg_lambda * torch.sum(self.beta**2)\n",
    "                for group_var in self.group_vars:\n",
    "                    reg_penalty += self.reg_lambda * torch.sum(self.b[group_var]**2)\n",
    "            else:\n",
    "                raise ValueError(\"regularization must be either 'L1', 'L2', or None\")\n",
    "        \n",
    "        return -total_ll + reg_penalty\n",
    "\n",
    "    def fit(self, lr=0.01, epochs=None, convergence=False, tol=1e-4, patience=5, \n",
    "            max_epochs=20000, verbose=True, check_interval=100):\n",
    "        \"\"\"\n",
    "        Fit the model with either a fixed number of epochs or automatic convergence detection.\n",
    "        \n",
    "        Args:\n",
    "            lr: learning rate for optimizer\n",
    "            epochs: number of training epochs (if None and convergence=True, will run until convergence)\n",
    "            convergence: whether to use automatic convergence detection\n",
    "            tol: tolerance for convergence (relative change in loss)\n",
    "            patience: number of consecutive checks that must show convergence\n",
    "            max_epochs: maximum number of epochs to run when using convergence detection\n",
    "            verbose: whether to print progress messages\n",
    "            check_interval: check for convergence every this many epochs\n",
    "        \"\"\"\n",
    "        optimizer = optim.Adam(self.params, lr=lr)\n",
    "        \n",
    "        # Handle the case when neither epochs nor convergence is specified\n",
    "        if epochs is None and not convergence:\n",
    "            epochs = 5000  # Default number of epochs\n",
    "        \n",
    "        # If using convergence detection\n",
    "        if convergence and epochs is None:\n",
    "            epochs = max_epochs\n",
    "            \n",
    "            # Initialize convergence tracking variables\n",
    "            best_loss = float('inf')\n",
    "            converged_count = 0\n",
    "            last_check_epoch = 0\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"Training with automatic convergence detection...\")\n",
    "                print(f\"Tolerance: {tol}, Patience: {patience}, Check interval: {check_interval}\")\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            loss = self.model_loglik()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            current_loss = loss.item()\n",
    "            self.loss_history.append(current_loss)\n",
    "            \n",
    "            # Print progress at regular intervals if verbose\n",
    "            if verbose and ((epoch % 500 == 0) or (epoch == epochs-1)):\n",
    "                print(f\"Epoch {epoch}: Negative Log-Likelihood = {current_loss:.4f}\")\n",
    "            \n",
    "            # Check for convergence if enabled\n",
    "            if convergence and epoch > 0 and epoch % check_interval == 0:\n",
    "                # Calculate relative improvement\n",
    "                relative_change = abs((current_loss - best_loss) / (best_loss + 1e-10))\n",
    "                \n",
    "                if relative_change < tol:\n",
    "                    converged_count += 1\n",
    "                    if verbose and converged_count == 1:\n",
    "                        print(f\"Epoch {epoch}: Potential convergence detected (relative change: {relative_change:.6f})\")\n",
    "                    if converged_count >= patience:\n",
    "                        if verbose:\n",
    "                            print(f\"Convergence achieved at epoch {epoch} (relative change: {relative_change:.6f})\")\n",
    "                        break\n",
    "                else:\n",
    "                    converged_count = 0\n",
    "                    \n",
    "                # Update best loss if current is better\n",
    "                if current_loss < best_loss:\n",
    "                    best_loss = current_loss\n",
    "                \n",
    "                last_check_epoch = epoch\n",
    "                    \n",
    "            # Stop early if we've reached max_epochs with convergence enabled\n",
    "            if convergence and epoch == epochs-1 and verbose:\n",
    "                print(f\"Warning: Reached maximum epochs ({max_epochs}) without converging\")\n",
    "        \n",
    "        # Store final model state\n",
    "        with torch.no_grad():\n",
    "            # Fixed effects\n",
    "            self.fixef = pd.Series(self.beta.detach().numpy().ravel(), index=self.fixed_colnames)\n",
    "            \n",
    "            # Create separate DataFrames for random effects of each grouping variable\n",
    "            self.ranef = {}\n",
    "            self.coef = {}\n",
    "            \n",
    "            for group_var in self.group_vars:\n",
    "                group_data = self.group_data[group_var]\n",
    "                random_effect_cols = group_data['random_effect_cols']\n",
    "                unique_groups = group_data['unique_groups']\n",
    "                \n",
    "                # Get variable names for this group's random effects\n",
    "                var_names = [self.fixed_colnames[i] for i in random_effect_cols]\n",
    "                \n",
    "                # Extract random effects matrix\n",
    "                ranef_matrix = self.b[group_var].detach().numpy()  # shape (G, d)\n",
    "                \n",
    "                # Create DataFrame for random effects\n",
    "                ranef_df = pd.DataFrame(ranef_matrix, columns=var_names)\n",
    "                ranef_df[group_var] = unique_groups\n",
    "                self.ranef[group_var] = ranef_df.set_index(group_var)\n",
    "                \n",
    "                # Create DataFrame that combines fixed and random effects\n",
    "                coef_df = pd.DataFrame(index=unique_groups)\n",
    "                \n",
    "                # Add random effect + fixed effect for each random term\n",
    "                for i, col_idx in enumerate(random_effect_cols):\n",
    "                    col_name = self.fixed_colnames[col_idx]\n",
    "                    coef_df[col_name] = ranef_matrix[:, i] + self.fixef[col_name]\n",
    "                \n",
    "                # Add remaining fixed effects (those without random effects)\n",
    "                for col_name in self.fixed_colnames:\n",
    "                    if col_name not in coef_df.columns and col_name in self.fixef.index:\n",
    "                        coef_df[col_name] = self.fixef[col_name]\n",
    "                \n",
    "                coef_df.index.name = group_var\n",
    "                self.coef[group_var] = coef_df.reset_index()\n",
    "                self.ranef[group_var] = self.ranef[group_var].reset_index()\n",
    "            \n",
    "            # Store convergence information\n",
    "            self.converged = converged_count >= patience if convergence else None\n",
    "            self.final_epoch = epoch\n",
    "            self.final_loss = self.loss_history[-1]\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"Final negative log-likelihood: {self.final_loss:.6f}\")\n",
    "                if convergence:\n",
    "                    print(f\"Training status: {'Converged' if self.converged else 'Not converged'}\")\n",
    "                    print(f\"Total epochs run: {self.final_epoch + 1}\")\n",
    "                \n",
    "    def predict(self, new_data=None, X_new=None, groups_new=None, return_probs=True):\n",
    "        \"\"\"\n",
    "        Predict on new data with support for multiple grouping variables and categorical variables.\n",
    "        \n",
    "        Args:\n",
    "            new_data: DataFrame with the same columns as used in training (preferred method)\n",
    "            X_new: fixed-effects design matrix (numpy array or DataFrame) \n",
    "            groups_new: dict mapping group name -> group values\n",
    "            return_probs: for binomial models, return probabilities (True) or expected counts (False)\n",
    "        \n",
    "        Returns:\n",
    "            Numpy array of predictions\n",
    "        \"\"\"\n",
    "        trials_new = None\n",
    "        \n",
    "        if self.formula is not None and new_data is not None:\n",
    "            # Process new data using formula parser\n",
    "            # Here we need to handle categorical variables consistently\n",
    "            \n",
    "            # For each categorical variable, create the same dummy variables as in training\n",
    "            X_parts = []\n",
    "            \n",
    "            # Start with processing categorical variables\n",
    "            for cat_var, encoding in self.cat_encodings.items():\n",
    "                if cat_var in new_data.columns:\n",
    "                    # Get the categorical variable from new data\n",
    "                    cat_data = new_data[cat_var]\n",
    "                    \n",
    "                    # Create dummy variables using the same categories as in training\n",
    "                    # Note: Some categories might be missing in new data\n",
    "                    dummies = pd.get_dummies(cat_data, prefix=cat_var)\n",
    "                    \n",
    "                    # Ensure we have the same dummy columns as in training\n",
    "                    for dummy_col in encoding['dummy_cols']:\n",
    "                        if dummy_col not in dummies.columns:\n",
    "                            # Add missing dummy column with zeros\n",
    "                            dummies[dummy_col] = 0\n",
    "                    \n",
    "                    # Keep only the columns we used in training (drop any new categories)\n",
    "                    dummies = dummies[encoding['dummy_cols']]\n",
    "                    \n",
    "                    # Add to X parts\n",
    "                    X_parts.append(dummies.values)\n",
    "            \n",
    "            # Extract groups from new data\n",
    "            groups_new = {}\n",
    "            for group_var in self.group_vars:\n",
    "                if group_var in new_data.columns:\n",
    "                    groups_new[group_var] = new_data[group_var].values\n",
    "                else:\n",
    "                    raise ValueError(f\"Grouping variable '{group_var}' not found in new_data\")\n",
    "            \n",
    "            # Now extract the numeric variables and add intercept\n",
    "            numeric_parts = []\n",
    "            if \"Intercept\" in self.fixed_colnames:\n",
    "                numeric_parts.append(np.ones((new_data.shape[0], 1)))\n",
    "            \n",
    "            # Find numeric columns (those not in categorical variables)\n",
    "            numeric_cols = [col for col in self.fixed_colnames \n",
    "                            if col not in [dummy for cat in self.cat_encodings.values() \n",
    "                                        for dummy in cat['dummy_cols']]\n",
    "                            and col != \"Intercept\"]\n",
    "            \n",
    "            if numeric_cols:\n",
    "                numeric_data = new_data[numeric_cols].values\n",
    "                numeric_parts.append(numeric_data)\n",
    "            \n",
    "            # Combine all parts\n",
    "            if numeric_parts:\n",
    "                X_parts = numeric_parts + X_parts\n",
    "            \n",
    "            # Combine all parts into design matrix\n",
    "            X_new = np.hstack(X_parts) if X_parts else None\n",
    "            \n",
    "            # Handle trials for binomial models\n",
    "            if self.distribution == 'binomial' and 'cbind' in self.formula:\n",
    "                lhs = self.formula.split(\"~\")[0].strip()\n",
    "                if lhs.startswith(\"cbind(\") and lhs.endswith(\")\"):\n",
    "                    inner = lhs[6:-1]\n",
    "                    success_var, failure_var = [s.strip() for s in inner.split(\",\")]\n",
    "                    if success_var in new_data and failure_var in new_data:\n",
    "                        successes = new_data[success_var].values\n",
    "                        failures = new_data[failure_var].values\n",
    "                        trials_new = successes + failures\n",
    "        else:\n",
    "            # Handle the case where X_new is provided directly\n",
    "            if X_new is None:\n",
    "                raise ValueError(\"Either new_data or X_new must be provided\")\n",
    "            \n",
    "            if isinstance(X_new, pd.DataFrame):\n",
    "                # Need to add intercept and handle categorical variables\n",
    "                if \"Intercept\" in self.fixed_colnames:\n",
    "                    X_new = np.hstack([np.ones((X_new.shape[0], 1)), X_new.values])\n",
    "                X_new = X_new.values\n",
    "            \n",
    "            # Ensure groups_new is a dictionary\n",
    "            if groups_new is not None and not isinstance(groups_new, dict):\n",
    "                # Convert to dict if single group\n",
    "                if len(self.group_vars) == 1:\n",
    "                    groups_new = {self.group_vars[0]: groups_new}\n",
    "                else:\n",
    "                    raise ValueError(\"groups_new must be a dictionary for models with multiple grouping variables\")\n",
    "        \n",
    "        # Convert to tensor\n",
    "        X_new = torch.tensor(X_new, dtype=torch.float32)\n",
    "        n_new = X_new.shape[0]\n",
    "        \n",
    "        if trials_new is not None:\n",
    "            trials_new = torch.tensor(trials_new, dtype=torch.float32).view(-1, 1)\n",
    "        \n",
    "        # Initialize prediction with fixed effects\n",
    "        eta_new = X_new @ self.beta.detach()\n",
    "        \n",
    "        # Add random effects contribution for each grouping variable\n",
    "        for group_var in self.group_vars:\n",
    "            if group_var not in groups_new:\n",
    "                continue  # Skip if group not provided\n",
    "                \n",
    "            group_data = self.group_data[group_var]\n",
    "            random_effect_cols = group_data['random_effect_cols']\n",
    "            d = group_data['d']\n",
    "            \n",
    "            # Build new Z matrix for this group\n",
    "            Z_new = np.zeros((n_new, d))\n",
    "            for j, col_idx in enumerate(random_effect_cols):\n",
    "                Z_new[:, j] = X_new[:, col_idx].detach().numpy().ravel()\n",
    "            Z_new = torch.tensor(Z_new, dtype=torch.float32)\n",
    "            \n",
    "            # Map groups to indices\n",
    "            group_to_index = {group: i for i, group in enumerate(group_data['unique_groups'])}\n",
    "            \n",
    "            # Get group indices with -1 for unseen groups\n",
    "            groups_array = groups_new[group_var]\n",
    "            group_indices = torch.tensor([\n",
    "                group_to_index.get(g, -1) for g in groups_array\n",
    "            ], dtype=torch.long)\n",
    "            \n",
    "            # Mask for seen/unseen groups\n",
    "            seen_mask = group_indices != -1\n",
    "            \n",
    "            # Allocate zero tensor for random effects\n",
    "            b_new = torch.zeros((len(groups_array), d), dtype=torch.float32)\n",
    "            \n",
    "            # Fill in values for seen groups\n",
    "            seen_indices = group_indices[seen_mask]\n",
    "            if len(seen_indices) > 0:\n",
    "                b_new[seen_mask] = self.b[group_var][seen_indices]\n",
    "            \n",
    "            # Add random effects contribution\n",
    "            rand_part = torch.sum(Z_new * b_new, dim=1, keepdim=True)\n",
    "            eta_new = eta_new + rand_part\n",
    "        \n",
    "        # Apply link function\n",
    "        mu_new = self.inverse_link(eta_new, self.link)\n",
    "        \n",
    "        # For binomial, return either probabilities or expected counts\n",
    "        if self.distribution == 'binomial' and not return_probs and trials_new is not None:\n",
    "            return (mu_new * trials_new).detach().numpy()\n",
    "        \n",
    "        return mu_new.detach().numpy()\n",
    "\n",
    "    def summary(self):\n",
    "        \"\"\"Display model summary information with support for multiple grouping variables and convergence information\"\"\"\n",
    "        # Fixed effects summary\n",
    "        print(\"Fixed Effects (beta):\")\n",
    "        fixed_effects_df = pd.DataFrame({\n",
    "            'Variable': self.fixed_colnames,\n",
    "            'Coefficient': self.beta.detach().numpy().ravel(),\n",
    "        })\n",
    "        print(fixed_effects_df)\n",
    "        \n",
    "        # Random effects variance components for each grouping variable\n",
    "        for group_var in self.group_vars:\n",
    "            print(f\"\\nRandom Effects for '{group_var}':\")\n",
    "            group_data = self.group_data[group_var]\n",
    "            random_effect_cols = group_data['random_effect_cols']\n",
    "            \n",
    "            print(\"Random Effects Std Dev (sigma_b) per component:\")\n",
    "            sigma_b = torch.exp(self.log_sigma_b[group_var]).detach().numpy()\n",
    "            \n",
    "            # Get variable names for each random effect\n",
    "            var_names = [self.fixed_colnames[i] for i in random_effect_cols]\n",
    "            \n",
    "            random_effects_df = pd.DataFrame({\n",
    "                'Variable': var_names,\n",
    "                'Std Dev': sigma_b\n",
    "            })\n",
    "            print(random_effects_df)\n",
    "        \n",
    "        # Distribution-specific parameters\n",
    "        if self.distribution == 'gaussian':\n",
    "            sigma_y = torch.exp(self.log_sigma_y).item()\n",
    "            print(f\"\\nResidual Std Dev (sigma_y): {sigma_y:.4f}\")\n",
    "        elif self.distribution == 'gamma':\n",
    "            phi = torch.exp(self.log_phi).item()\n",
    "            print(f\"\\nGamma shape parameter (phi): {phi:.4f}\")\n",
    "            \n",
    "        # Model fit statistics\n",
    "        print(\"\\nModel Information:\")\n",
    "        print(f\"Distribution: {self.distribution}\")\n",
    "        print(f\"Link function: {self.link}\")\n",
    "        print(f\"Number of observations: {self.n}\")\n",
    "        \n",
    "        # Print number of groups for each grouping variable\n",
    "        for group_var in self.group_vars:\n",
    "            n_groups = self.group_data[group_var]['n_groups']\n",
    "            print(f\"Number of groups in '{group_var}': {n_groups}\")\n",
    "        \n",
    "        # Print categorical variable information\n",
    "        if hasattr(self, 'cat_encodings') and self.cat_encodings:\n",
    "            print(\"\\nCategorical Variables:\")\n",
    "            for cat_var, encoding in self.cat_encodings.items():\n",
    "                n_categories = len(encoding['categories'])\n",
    "                print(f\"  - {cat_var}: {n_categories} categories\")\n",
    "        \n",
    "        # Print convergence information if available\n",
    "        if hasattr(self, 'converged'):\n",
    "            print(\"\\nConvergence Information:\")\n",
    "            print(f\"Converged: {self.converged}\")\n",
    "            print(f\"Total epochs: {self.final_epoch + 1}\")\n",
    "            print(f\"Final negative log-likelihood: {self.final_loss:.6f}\")\n",
    "        else:\n",
    "            print(f\"\\nFinal negative log-likelihood: {self.loss_history[-1]:.4f}\")\n",
    "            \n",
    "    def plot_loss(self):\n",
    "        \"\"\"Plot the loss history with convergence indication if available\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.loss_history)\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Negative Log-Likelihood\")\n",
    "        plt.title(\"Training Loss History\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Mark convergence point if available\n",
    "        if hasattr(self, 'converged') and self.converged:\n",
    "            # Find approximate convergence point - when loss stabilizes\n",
    "            # This is a simple heuristic - could be made more sophisticated\n",
    "            loss_arr = np.array(self.loss_history)\n",
    "            window_size = min(100, len(loss_arr) // 10)\n",
    "            if window_size > 0:\n",
    "                # Calculate rolling average to smooth the curve\n",
    "                rolling_mean = np.convolve(loss_arr, np.ones(window_size)/window_size, mode='valid')\n",
    "                # Estimate where convergence happened\n",
    "                diffs = np.abs(np.diff(rolling_mean))\n",
    "                conv_point = np.argmax(diffs < 1e-4) + window_size // 2\n",
    "                conv_point = min(conv_point, len(self.loss_history) - 1)\n",
    "                \n",
    "                plt.axvline(x=conv_point, color='r', linestyle='--', \n",
    "                            label=f'Convergence ~epoch {conv_point}')\n",
    "                plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_residuals(self):\n",
    "        \"\"\"Plot residuals vs fitted values\"\"\"\n",
    "        with torch.no_grad():\n",
    "            b_obs = self.b[self.group_idx]\n",
    "            rand_part = torch.sum(self.Z * b_obs, dim=1, keepdim=True)\n",
    "            eta = self.X @ self.beta + rand_part\n",
    "            mu = self.inverse_link(eta, self.link)\n",
    "            \n",
    "            if self.distribution == 'binomial' and self.trials is not None:\n",
    "                # For binomial with trials, scale residuals appropriately\n",
    "                expected = mu * self.trials\n",
    "                residuals = self.y - expected\n",
    "                # Pearson residuals: (observed - expected) / sqrt(Var(Y))\n",
    "                var_y = expected * (1 - mu) \n",
    "                pearson_residuals = residuals / torch.sqrt(var_y)\n",
    "                resid = pearson_residuals.detach().numpy().ravel()\n",
    "                title = \"Pearson Residuals vs Fitted\"\n",
    "            else:\n",
    "                residuals = self.y - mu\n",
    "                resid = residuals.detach().numpy().ravel()\n",
    "                title = \"Residuals vs Fitted\"\n",
    "                \n",
    "        fitted = mu.detach().numpy().ravel()\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(fitted, resid, alpha=0.6)\n",
    "        plt.xlabel(\"Fitted values (probabilities)\")\n",
    "        plt.ylabel(\"Residuals\")\n",
    "        plt.title(title)\n",
    "        plt.axhline(0, color='red', linestyle='--')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_random_effects(self, component=None):\n",
    "        \"\"\"\n",
    "        Plot random effects distribution\n",
    "        \n",
    "        Args:\n",
    "            component: Index or name of random effect component to plot.\n",
    "                      If None, plots all components.\n",
    "        \"\"\"\n",
    "        ranef_values = self.b.detach().numpy()\n",
    "        \n",
    "        if component is not None:\n",
    "            # Plot a specific component\n",
    "            if isinstance(component, str):\n",
    "                # Find index by name\n",
    "                component_names = [self.fixed_colnames[i] for i in self.random_effect_cols]\n",
    "                if component not in component_names:\n",
    "                    raise ValueError(f\"Component '{component}' not found in random effects\")\n",
    "                component_idx = component_names.index(component)\n",
    "            else:\n",
    "                component_idx = component\n",
    "                \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            component_name = self.fixed_colnames[self.random_effect_cols[component_idx]]\n",
    "            plt.hist(ranef_values[:, component_idx], bins=20, alpha=0.7)\n",
    "            plt.xlabel(f\"Random effect value for {component_name}\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.title(f\"Distribution of Random Effects: {component_name}\")\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.axvline(0, color='red', linestyle='--')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            # Plot all components\n",
    "            component_names = [self.fixed_colnames[i] for i in self.random_effect_cols]\n",
    "            n_components = len(component_names)\n",
    "            \n",
    "            fig, axes = plt.subplots(n_components, 1, figsize=(10, 4*n_components))\n",
    "            if n_components == 1:\n",
    "                axes = [axes]\n",
    "                \n",
    "            for i, name in enumerate(component_names):\n",
    "                axes[i].hist(ranef_values[:, i], bins=20, alpha=0.7)\n",
    "                axes[i].set_xlabel(f\"Random effect value\")\n",
    "                axes[i].set_ylabel(\"Frequency\")\n",
    "                axes[i].set_title(f\"Distribution of Random Effects: {name}\")\n",
    "                axes[i].grid(True, alpha=0.3)\n",
    "                axes[i].axvline(0, color='red', linestyle='--')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f7d507d-f6f0-4ce9-b81e-62e3ebc2a0b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Exemplos de Uso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ed69cef-dac5-4366-93bd-1f43a2c5ec3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Example 1: Basic Gaussian Mixed Model with Random Intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18ccc7fb-436c-4e54-9241-92f4a1b17eda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Negative Log-Likelihood = 7832638.5000\nEpoch 500: Negative Log-Likelihood = 243329.5156\nEpoch 1000: Negative Log-Likelihood = 87079.5234\nEpoch 1500: Negative Log-Likelihood = 46315.0391\nEpoch 2000: Negative Log-Likelihood = 29400.6621\nEpoch 2500: Negative Log-Likelihood = 20732.7617\nEpoch 3000: Negative Log-Likelihood = 15725.7812\nEpoch 3500: Negative Log-Likelihood = 12608.2930\nEpoch 4000: Negative Log-Likelihood = 10569.5801\nEpoch 4500: Negative Log-Likelihood = 9192.6152\nEpoch 4999: Negative Log-Likelihood = 8245.1514\nFinal negative log-likelihood: 8245.151367\nFixed Effects (beta):\n  Variable  Coefficient\n0       x1     3.902035\n1       x2     3.971525\n2       x3     4.023691\n\nRandom Effects for 'Group':\nRandom Effects Std Dev (sigma_b) per component:\n  Variable   Std Dev\n0       x1  3.772491\n\nResidual Std Dev (sigma_y): 44.0583\n\nModel Information:\nDistribution: gaussian\nLink function: identity\nNumber of observations: 1000\nNumber of groups in 'Group': 20\n\nConvergence Information:\nConverged: None\nTotal epochs: 5000\nFinal negative log-likelihood: 8245.151367\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[-7.1496315]\n [ 1.9804437]\n [14.63451  ]\n [ 7.954462 ]\n [11.129111 ]\n [ 7.5537705]\n [ 7.961314 ]\n [-3.4060128]\n [-4.511882 ]\n [-3.4270325]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Create synthetic data\n",
    "n_samples = 1000\n",
    "n_groups = 20\n",
    "X, y = make_regression(n_samples=n_samples, n_features=3, noise=0.5)\n",
    "groups = np.random.choice(range(n_groups), size=n_samples)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'x1': X[:, 0],\n",
    "    'x2': X[:, 1], \n",
    "    'x3': X[:, 2],\n",
    "    'y': y,\n",
    "    'group': groups\n",
    "})\n",
    "\n",
    "# Fit a Gaussian mixed model with random intercept\n",
    "model = GLMM(\n",
    "    X=data[['x1', 'x2', 'x3']],\n",
    "    y=data['y'],\n",
    "    groups={'Group': data['group']},\n",
    "    distribution='gaussian',\n",
    "    link='identity',\n",
    "    random_effect_cols={'Group': [0]}  # Random intercept (corresponds to intercept column)\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(lr=0.01, epochs=5000, verbose=True)\n",
    "\n",
    "# Examine results\n",
    "model.summary()\n",
    "model.plot_loss()\n",
    "\n",
    "# Make predictions\n",
    "new_data = pd.DataFrame({\n",
    "    'x1': np.random.normal(size=10),\n",
    "    'x2': np.random.normal(size=10),\n",
    "    'x3': np.random.normal(size=10),\n",
    "    'group': np.random.choice(range(n_groups), size=10)\n",
    "})\n",
    "\n",
    "predictions = model.predict(X_new=new_data[['x1', 'x2', 'x3']], groups_new={'Group': new_data['group']})\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9b855c7-f645-47a6-89cd-1e3eb1634aa3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Example 2: Using Formula Notation with Random Slopes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bd51861-b177-47f0-ae65-c0dd7ef093e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with automatic convergence detection...\nTolerance: 0.0001, Patience: 5, Check interval: 100\nEpoch 0: Negative Log-Likelihood = 5439992.0000\nEpoch 500: Negative Log-Likelihood = 155384.4531\nEpoch 1000: Negative Log-Likelihood = 55034.3711\nEpoch 1500: Negative Log-Likelihood = 28992.5176\nEpoch 2000: Negative Log-Likelihood = 18207.2832\nEpoch 2500: Negative Log-Likelihood = 12682.5264\nEpoch 3000: Negative Log-Likelihood = 9488.8154\nEpoch 3500: Negative Log-Likelihood = 7496.5498\nEpoch 4000: Negative Log-Likelihood = 6189.5439\nEpoch 4500: Negative Log-Likelihood = 5302.5659\nEpoch 5000: Negative Log-Likelihood = 4687.0879\nEpoch 5500: Negative Log-Likelihood = 4254.2036\nEpoch 6000: Negative Log-Likelihood = 3947.8123\nEpoch 6500: Negative Log-Likelihood = 3730.9316\nEpoch 7000: Negative Log-Likelihood = 3578.2812\nEpoch 7500: Negative Log-Likelihood = 3472.0098\nEpoch 8000: Negative Log-Likelihood = 3399.1538\nEpoch 8500: Negative Log-Likelihood = 3350.0244\nEpoch 9000: Negative Log-Likelihood = 3317.1719\nEpoch 9500: Negative Log-Likelihood = 3294.6729\nEpoch 10000: Negative Log-Likelihood = 3277.5225\nEpoch 10500: Negative Log-Likelihood = 3260.6321\nEpoch 11000: Negative Log-Likelihood = 3232.6133\nEpoch 11500: Negative Log-Likelihood = 2839.0881\nEpoch 12000: Negative Log-Likelihood = 2867.7244\nEpoch 12500: Negative Log-Likelihood = 2773.3345\nEpoch 13000: Negative Log-Likelihood = 2754.4761\nEpoch 13500: Negative Log-Likelihood = 2826.8777\nEpoch 14000: Negative Log-Likelihood = 2671.0103\nEpoch 14500: Negative Log-Likelihood = 2699.8667\nEpoch 15000: Negative Log-Likelihood = 2624.4023\nEpoch 15500: Negative Log-Likelihood = 2595.8142\nEpoch 16000: Negative Log-Likelihood = 2653.3511\nEpoch 16500: Negative Log-Likelihood = 2523.2483\nEpoch 17000: Negative Log-Likelihood = 2489.7446\nEpoch 17500: Negative Log-Likelihood = 2399.6636\nEpoch 18000: Negative Log-Likelihood = 2046.3491\nEpoch 18500: Negative Log-Likelihood = 2083.1245\nEpoch 19000: Negative Log-Likelihood = 1934.7311\nEpoch 19500: Negative Log-Likelihood = 1892.4915\nEpoch 20000: Negative Log-Likelihood = 1878.9720\nEpoch 20500: Negative Log-Likelihood = 1811.5786\nEpoch 21000: Negative Log-Likelihood = 1866.1519\nEpoch 21500: Negative Log-Likelihood = 1690.3921\nEpoch 22000: Negative Log-Likelihood = 1697.5281\nEpoch 22500: Negative Log-Likelihood = 1557.9343\nEpoch 23000: Negative Log-Likelihood = 1640.3696\nEpoch 23500: Negative Log-Likelihood = 1442.1780\nEpoch 24000: Negative Log-Likelihood = 1382.7430\nEpoch 24500: Negative Log-Likelihood = 1241.1340\nEpoch 25000: Negative Log-Likelihood = 1186.8713\nEpoch 25500: Negative Log-Likelihood = 1089.0952\nEpoch 26000: Negative Log-Likelihood = 1003.7975\nEpoch 26500: Negative Log-Likelihood = 1017.9916\nEpoch 27000: Negative Log-Likelihood = 1013.8334\nEpoch 27500: Negative Log-Likelihood = 1010.6507\nEpoch 28000: Negative Log-Likelihood = 1047.3285\nEpoch 28500: Negative Log-Likelihood = 1103.6780\nEpoch 29000: Negative Log-Likelihood = 1036.8318\nEpoch 29500: Negative Log-Likelihood = 1046.1628\nEpoch [REDACTED]: Negative Log-Likelihood = 1072.8477\nEpoch 30500: Negative Log-Likelihood = 1465.4778\nEpoch 31000: Negative Log-Likelihood = 1043.7473\nEpoch 31500: Negative Log-Likelihood = 1015.6286\nEpoch 32000: Negative Log-Likelihood = 1014.8933\nEpoch 32500: Negative Log-Likelihood = 1122.1498\nEpoch 33000: Negative Log-Likelihood = 1041.5735\nEpoch 33500: Negative Log-Likelihood = 1233.3735\nEpoch 34000: Negative Log-Likelihood = 1165.9270\nEpoch 34500: Negative Log-Likelihood = 1035.7563\nEpoch 35000: Negative Log-Likelihood = 1020.5818\nEpoch 35500: Negative Log-Likelihood = 1011.5920\nEpoch 36000: Negative Log-Likelihood = 1027.7145\nEpoch 36500: Negative Log-Likelihood = 1073.5803\nEpoch 37000: Negative Log-Likelihood = 1132.7505\nEpoch 37500: Negative Log-Likelihood = 1010.9587\nEpoch 38000: Negative Log-Likelihood = 1155.7627\nEpoch 38500: Negative Log-Likelihood = 1023.7026\nEpoch 39000: Negative Log-Likelihood = 1118.2649\nEpoch 39500: Negative Log-Likelihood = 1040.5598\nEpoch 40000: Negative Log-Likelihood = 1023.3745\nEpoch 40500: Negative Log-Likelihood = 1187.4338\nEpoch 41000: Negative Log-Likelihood = 1210.9146\nEpoch 41500: Negative Log-Likelihood = 1107.3885\nEpoch 42000: Negative Log-Likelihood = 1048.5083\nEpoch 42500: Negative Log-Likelihood = 1012.8782\nEpoch 43000: Negative Log-Likelihood = 1026.0402\nEpoch 43500: Negative Log-Likelihood = 1056.9182\nEpoch 44000: Negative Log-Likelihood = 1022.9774\nEpoch 44500: Negative Log-Likelihood = 1058.5465\nEpoch 45000: Negative Log-Likelihood = 1076.3220\nEpoch 45500: Negative Log-Likelihood = 1151.2327\nEpoch 46000: Negative Log-Likelihood = 1028.2336\nEpoch 46500: Negative Log-Likelihood = 1024.8740\nEpoch 47000: Negative Log-Likelihood = 1026.9603\nEpoch 47500: Negative Log-Likelihood = 1026.7766\nEpoch 48000: Negative Log-Likelihood = 1012.5894\nEpoch 48500: Negative Log-Likelihood = 1035.9229\nEpoch 49000: Negative Log-Likelihood = 1032.8308\nEpoch 49500: Negative Log-Likelihood = 1035.7838\nEpoch 50000: Negative Log-Likelihood = 1063.0480\nEpoch 50500: Negative Log-Likelihood = 1027.7820\nEpoch 51000: Negative Log-Likelihood = 1199.9895\nEpoch 51500: Negative Log-Likelihood = 1064.8513\nEpoch 52000: Negative Log-Likelihood = 1038.7136\nEpoch 52500: Negative Log-Likelihood = 1041.3135\nEpoch 53000: Negative Log-Likelihood = 1068.9924\nEpoch 53500: Negative Log-Likelihood = 1032.5377\nEpoch 54000: Negative Log-Likelihood = 1048.5583\nEpoch 54500: Negative Log-Likelihood = 1046.5889\nEpoch 55000: Negative Log-Likelihood = 1015.1680\nEpoch 55500: Negative Log-Likelihood = 1055.5809\nEpoch 56000: Negative Log-Likelihood = 1037.1682\nEpoch 56500: Negative Log-Likelihood = 1012.6597\nEpoch 57000: Negative Log-Likelihood = 1034.4047\nEpoch 57500: Negative Log-Likelihood = 1014.7388\nEpoch 58000: Negative Log-Likelihood = 1041.3065\nEpoch 58500: Negative Log-Likelihood = 1039.1669\nEpoch 59000: Negative Log-Likelihood = 1006.8483\nEpoch 59500: Negative Log-Likelihood = 1033.8333\nEpoch 60000: Negative Log-Likelihood = 1007.8570\nEpoch 60500: Negative Log-Likelihood = 1061.0688\nEpoch 61000: Negative Log-Likelihood = 1008.9157\nEpoch 61500: Negative Log-Likelihood = 1062.0139\nEpoch 62000: Negative Log-Likelihood = 1030.0315\nEpoch 62500: Negative Log-Likelihood = 1264.8374\nEpoch 63000: Negative Log-Likelihood = 1010.6928\nEpoch 63500: Negative Log-Likelihood = 1050.6941\nEpoch 64000: Negative Log-Likelihood = 1124.2672\nEpoch 64500: Negative Log-Likelihood = 1040.8464\nEpoch 65000: Negative Log-Likelihood = 1006.6940\nEpoch 65500: Negative Log-Likelihood = 1022.6771\nEpoch 66000: Negative Log-Likelihood = 1018.4572\nEpoch 66500: Negative Log-Likelihood = 1052.9570\nEpoch 67000: Negative Log-Likelihood = 1045.8950\nEpoch 67500: Negative Log-Likelihood = 1008.9169\nEpoch 68000: Negative Log-Likelihood = 1032.3004\nEpoch 68500: Negative Log-Likelihood = 1016.6215\nEpoch 69000: Negative Log-Likelihood = 1181.6708\nEpoch 69500: Negative Log-Likelihood = 1036.7848\nEpoch 70000: Negative Log-Likelihood = 1014.2074\nEpoch 70500: Negative Log-Likelihood = 1038.1592\nEpoch 71000: Negative Log-Likelihood = 1011.6071\nEpoch 71500: Negative Log-Likelihood = 1025.4878\nEpoch 72000: Negative Log-Likelihood = 1061.9412\nEpoch 72500: Negative Log-Likelihood = 1136.8789\nEpoch 73000: Negative Log-Likelihood = 1037.6458\nEpoch 73500: Negative Log-Likelihood = 1026.1235\nEpoch 74000: Negative Log-Likelihood = 1082.7537\nEpoch 74500: Negative Log-Likelihood = 1026.4980\nEpoch 75000: Negative Log-Likelihood = 1331.5438\nEpoch 75500: Negative Log-Likelihood = 1009.1818\nEpoch 76000: Negative Log-Likelihood = 1168.7600\nEpoch 76500: Negative Log-Likelihood = 1015.8992\nEpoch 77000: Negative Log-Likelihood = 1074.1338\nEpoch 77500: Negative Log-Likelihood = 1025.7458\nEpoch 78000: Negative Log-Likelihood = 1025.1034\nEpoch 78500: Negative Log-Likelihood = 1044.6720\nEpoch 79000: Negative Log-Likelihood = 1131.2749\nEpoch 79500: Negative Log-Likelihood = 1004.6567\nEpoch 80000: Negative Log-Likelihood = 1037.6677\nEpoch 80500: Negative Log-Likelihood = 1056.3020\nEpoch 81000: Negative Log-Likelihood = 1107.9768\nEpoch 81500: Negative Log-Likelihood = 1036.8048\nEpoch 82000: Negative Log-Likelihood = 1026.9807\nEpoch 82500: Negative Log-Likelihood = 1175.5254\nEpoch 83000: Negative Log-Likelihood = 1037.1862\nEpoch 83500: Negative Log-Likelihood = 1006.1420\nEpoch 84000: Negative Log-Likelihood = 1032.6653\nEpoch 84500: Negative Log-Likelihood = 1057.4236\nEpoch 85000: Negative Log-Likelihood = 1097.5167\nEpoch 85500: Negative Log-Likelihood = 1025.7642\nEpoch 86000: Negative Log-Likelihood = 1109.1726\nEpoch 86500: Negative Log-Likelihood = 1241.3163\nEpoch 87000: Negative Log-Likelihood = 1009.9744\nEpoch 87500: Negative Log-Likelihood = 1008.6401\nEpoch 88000: Negative Log-Likelihood = 1018.3687\nEpoch 88500: Negative Log-Likelihood = 1014.8846\nEpoch 89000: Negative Log-Likelihood = 1138.2079\nEpoch 89500: Negative Log-Likelihood = 1023.3415\nEpoch 90000: Negative Log-Likelihood = 1013.1996\nEpoch 90500: Negative Log-Likelihood = 1027.7917\nEpoch 91000: Negative Log-Likelihood = 1149.8766\nEpoch 91500: Negative Log-Likelihood = 1028.4204\nEpoch 92000: Negative Log-Likelihood = 1008.0627\nEpoch 92500: Negative Log-Likelihood = 1024.7368\nEpoch 93000: Negative Log-Likelihood = 1011.6552\nEpoch 93500: Negative Log-Likelihood = 1034.7034\nEpoch 94000: Negative Log-Likelihood = 1059.7646\nEpoch 94500: Negative Log-Likelihood = 1025.7108\nEpoch 95000: Negative Log-Likelihood = 1228.7035\nEpoch 95500: Negative Log-Likelihood = 1026.7194\nEpoch 96000: Negative Log-Likelihood = 1057.4128\nEpoch 96500: Negative Log-Likelihood = 1033.4408\nEpoch 97000: Negative Log-Likelihood = 1435.4573\nEpoch 97500: Negative Log-Likelihood = 1688.6467\nEpoch 98000: Negative Log-Likelihood = 1019.1031\nEpoch 98500: Negative Log-Likelihood = 1014.1710\nEpoch 99000: Negative Log-Likelihood = 1187.5321\nEpoch 99500: Negative Log-Likelihood = 1021.6949\nEpoch 99999: Negative Log-Likelihood = 1233.8132\nWarning: Reached maximum epochs (100000) without converging\nFinal negative log-likelihood: 1233.813232\nTraining status: Not converged\nTotal epochs run: 100000\n\nRandom Effects by School:\n      school     Intercept  hours_studied\n0   School_0  3.227172e-08   5.650196e-06\n1   School_1 -1.756276e-07  -8.729087e-07\n2  School_10  1.747352e-03  -3.329289e-07\n3  School_11  1.038068e-03   3.851845e-07\n4  School_12 -5.376208e-08  -4.147325e-07\n5  School_13  3.446926e-08   2.493703e-07\n6  School_14 -1.356091e-07  -3.077142e-07\n7  School_15 -2.234628e-07  -1.623990e-06\n8  School_16 -1.758989e-03  -5.110617e-07\n9  School_17  4.219881e-08   1.266359e-06\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nPredicted scores for new students:\nStudent at School_28: math=0.89, study=5.75, private=1 → predicted score: 160.41\nStudent at School_30: math=0.84, study=11.53, private=1 → predicted score: 183.45\nStudent at School_40: math=-0.88, study=4.59, private=0 → predicted score: 144.75\nStudent at School_32: math=0.28, study=1.06, private=0 → predicted score: 136.18\nStudent at School_47: math=0.40, study=9.58, private=0 → predicted score: 171.03\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate synthetic data\n",
    "n_samples = 500\n",
    "n_schools = 25\n",
    "n_students_per_school = n_samples // n_schools\n",
    "\n",
    "schools = np.repeat(range(n_schools), n_students_per_school)\n",
    "math_aptitude = np.random.normal(0, 1, n_samples)\n",
    "hours_studied = np.random.gamma(shape=2, scale=2, size=n_samples)\n",
    "is_private = np.random.choice([0, 1], size=n_samples, p=[0.7, 0.3])\n",
    "\n",
    "# Create random intercepts and slopes per school\n",
    "school_intercepts = np.random.normal(70, 5, n_schools)\n",
    "school_slopes = np.random.normal(2, 0.5, n_schools)\n",
    "\n",
    "# Generate test scores with both fixed and random effects\n",
    "base_score = 60 + 5 * math_aptitude + 2 * hours_studied + 3 * is_private\n",
    "school_effect = np.array([school_intercepts[s] for s in schools])\n",
    "study_effect = np.array([school_slopes[s] * hours_studied[i] for i, s in enumerate(schools)])\n",
    "scores = base_score + school_effect + study_effect + np.random.normal(0, 5, n_samples)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'student_id': range(n_samples),\n",
    "    'school': [f\"School_{i}\" for i in schools],\n",
    "    'math_aptitude': math_aptitude,\n",
    "    'hours_studied': hours_studied,\n",
    "    'is_private': is_private,\n",
    "    'score': scores\n",
    "})\n",
    "\n",
    "# Fit the model using formula notation with random slope\n",
    "model = GLMM(\n",
    "    formula=\"score ~ math_aptitude + hours_studied + is_private + (1 + hours_studied | school)\",\n",
    "    data=data,\n",
    "    distribution='gaussian'\n",
    ")\n",
    "\n",
    "# Train with automatic convergence detection\n",
    "model.fit(lr=0.01, convergence=True, tol=1e-4, verbose=True)\n",
    "\n",
    "# Check the random effects\n",
    "print(\"\\nRandom Effects by School:\")\n",
    "print(model.ranef['school'].head(10))\n",
    "\n",
    "# Visualize\n",
    "model.plot_loss()\n",
    "\n",
    "# Make predictions for new students\n",
    "new_students = pd.DataFrame({\n",
    "    'math_aptitude': np.random.normal(0, 1, 5),\n",
    "    'hours_studied': np.random.gamma(shape=2, scale=2, size=5),\n",
    "    'is_private': np.random.choice([0, 1], size=5),\n",
    "    'school': np.random.choice(data['school'].unique(), size=5)\n",
    "})\n",
    "\n",
    "predicted_scores = model.predict(new_data=new_students)\n",
    "print(\"\\nPredicted scores for new students:\")\n",
    "for i, (idx, student) in enumerate(new_students.iterrows()):\n",
    "    print(f\"Student at {student['school']}: math={student['math_aptitude']:.2f}, \"\n",
    "          f\"study={student['hours_studied']:.2f}, private={student['is_private']} → \"\n",
    "          f\"predicted score: {predicted_scores[i][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c2bb365-00ed-4d01-8b48-bd6a115ee7be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Example 3: Binomial Model for Survey Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3d82a84-dc23-464b-b444-95e6933fcbd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Negative Log-Likelihood = 7161.2080\nEpoch 500: Negative Log-Likelihood = 4895.9814\nEpoch 1000: Negative Log-Likelihood = 4871.9536\nEpoch 1500: Negative Log-Likelihood = 4775.9458\nEpoch 2000: Negative Log-Likelihood = 4777.8530\nEpoch 2500: Negative Log-Likelihood = 4761.7598\nEpoch 2999: Negative Log-Likelihood = 4759.3335\nFinal negative log-likelihood: 4759.333496\nFixed Effects (beta):\n    Variable  Coefficient\n0  Intercept     0.460474\n1        age     0.008303\n2  education     0.168424\n3   gender_O    -0.053889\n\nRandom Effects for 'respondent_id':\nRandom Effects Std Dev (sigma_b) per component:\n    Variable  Std Dev\n0  Intercept  0.00045\n\nRandom Effects for 'question_id':\nRandom Effects Std Dev (sigma_b) per component:\n    Variable   Std Dev\n0  Intercept  0.712727\n\nModel Information:\nDistribution: binomial\nLink function: logit\nNumber of observations: 10000\nNumber of groups in 'respondent_id': 50\nNumber of groups in 'question_id': 200\n\nConvergence Information:\nConverged: None\nTotal epochs: 3000\nFinal negative log-likelihood: 4759.333496\n\nRespondent Random Effects (first 10):\n  respondent_id     Intercept\n0            R1 -1.015357e-06\n1           R10  8.567106e-07\n2           R11 -5.144001e-07\n3           R12 -3.858482e-07\n4           R13  1.001686e-06\n5           R14  5.311032e-07\n6           R15 -5.226393e-07\n7           R16  1.149340e-06\n8           R17  8.856211e-07\n9           R18 -5.594322e-07\n\nQuestion Random Effects (first 10):\n  question_id  Intercept\n0          Q1  -0.076710\n1         Q10  -0.944620\n2        Q100  -0.166559\n3        Q101  -0.076710\n4        Q102   0.976138\n5        Q103   0.825902\n6        Q104   0.558055\n7        Q105   0.323701\n8        Q106  -0.337297\n9        Q107  -1.156395\n\nPredicted probabilities of correct response:\nRespondent R8 on question Q200: 0.541\nRespondent R39 on question Q47: 0.680\nRespondent R32 on question Q32: 0.737\nRespondent R2 on question Q75: 0.631\nRespondent R35 on question Q29: 0.711\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate synthetic survey data\n",
    "n_questions = 200\n",
    "n_respondents = 50\n",
    "\n",
    "# Respondent characteristics\n",
    "age = np.random.uniform(18, 70, n_respondents)\n",
    "education = np.random.choice([1, 2, 3, 4], size=n_respondents)  # 1=HS, 2=College, 3=Masters, 4=PhD\n",
    "gender = np.random.choice(['M', 'F', 'O'], size=n_respondents, p=[0.48, 0.48, 0.04])\n",
    "\n",
    "# Question difficulty and discrimination\n",
    "difficulty = np.random.normal(0, 1, n_questions)\n",
    "\n",
    "# Response data\n",
    "data_rows = []\n",
    "for r in range(n_respondents):\n",
    "    for q in range(n_questions):\n",
    "        # Probability of correct answer based on respondent ability and question difficulty\n",
    "        respondent_ability = 0.5 + 0.01 * age[r] + 0.2 * education[r] + np.random.normal(0, 0.5)\n",
    "        p_correct = 1 / (1 + np.exp(-(respondent_ability - difficulty[q])))\n",
    "        \n",
    "        # Generate success/failure\n",
    "        correct = np.random.binomial(1, p_correct)\n",
    "        incorrect = 1 - correct\n",
    "        \n",
    "        data_rows.append({\n",
    "            'respondent_id': f\"R{r+1}\",\n",
    "            'question_id': f\"Q{q+1}\",\n",
    "            'age': age[r],\n",
    "            'education': education[r],\n",
    "            'gender': gender[r],\n",
    "            'correct': correct,\n",
    "            'incorrect': incorrect\n",
    "        })\n",
    "\n",
    "survey_data = pd.DataFrame(data_rows)\n",
    "\n",
    "# Create dummy variables for gender\n",
    "gender_dummies = pd.get_dummies(survey_data['gender'], prefix='gender', drop_first=True)\n",
    "survey_data = pd.concat([survey_data, gender_dummies], axis=1)\n",
    "\n",
    "# Fit a binomial GLMM with random intercepts for both respondents and questions\n",
    "model = GLMM(\n",
    "    formula=\"cbind(correct, incorrect) ~ age + education + gender_F + gender_O + (1 | respondent_id) + (1 | question_id)\",\n",
    "    data=survey_data,\n",
    "    distribution='binomial',\n",
    "    link='logit'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(lr=0.01, epochs=3000, verbose=True)\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Examine respondent random effects\n",
    "print(\"\\nRespondent Random Effects (first 10):\")\n",
    "print(model.ranef['respondent_id'].head(10))\n",
    "\n",
    "# Examine question random effects\n",
    "print(\"\\nQuestion Random Effects (first 10):\")\n",
    "print(model.ranef['question_id'].head(10))\n",
    "\n",
    "# Predict probability of correct response for new data\n",
    "new_responses = pd.DataFrame({\n",
    "    'respondent_id': np.random.choice(survey_data['respondent_id'].unique(), size=5),\n",
    "    'question_id': np.random.choice(survey_data['question_id'].unique(), size=5),\n",
    "    'age': np.random.uniform(18, 70, 5),\n",
    "    'education': np.random.choice([1, 2, 3, 4], size=5),\n",
    "    'gender': np.random.choice(['M', 'F', 'O'], size=5)\n",
    "})\n",
    "\n",
    "# Create the same dummy variables as in training\n",
    "gender_dummies = pd.get_dummies(new_responses['gender'], prefix='gender', drop_first=True)\n",
    "for col in ['gender_F', 'gender_O']:\n",
    "    if col not in gender_dummies:\n",
    "        gender_dummies[col] = 0\n",
    "new_responses = pd.concat([new_responses, gender_dummies], axis=1)\n",
    "\n",
    "# Predict probabilities\n",
    "predicted_probs = model.predict(new_data=new_responses)\n",
    "print(\"\\nPredicted probabilities of correct response:\")\n",
    "for i, (idx, resp) in enumerate(new_responses.iterrows()):\n",
    "    print(f\"Respondent {resp['respondent_id']} on question {resp['question_id']}: {predicted_probs[i][0]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82467eea-faae-4a4f-aa5a-f13f2f2e5e51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Example 4: Poisson Model for Count Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c2f75a9-60a8-4378-9d59-12030ed8af75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Negative Log-Likelihood = 8884.4658\nEpoch 500: Negative Log-Likelihood = 495.2489\nEpoch 1000: Negative Log-Likelihood = 487.8095\nEpoch 1500: Negative Log-Likelihood = 487.6596\nEpoch 2000: Negative Log-Likelihood = 487.6259\nEpoch 2500: Negative Log-Likelihood = 487.5924\nEpoch 2999: Negative Log-Likelihood = 487.5606\nFinal negative log-likelihood: 487.560577\nFixed Effects (beta):\n      Variable  Coefficient\n0    Intercept     1.378686\n1  temperature     0.053341\n2   wind_speed    -0.096175\n3   is_weekend     0.575471\n\nRandom Effects for 'angler_id':\nRandom Effects Std Dev (sigma_b) per component:\n    Variable   Std Dev\n0  Intercept  0.889273\n\nRandom Effects for 'location_id':\nRandom Effects Std Dev (sigma_b) per component:\n    Variable  Std Dev\n0  Intercept  1.03044\n\nModel Information:\nDistribution: poisson\nLink function: log\nNumber of observations: 200\nNumber of groups in 'angler_id': 47\nNumber of groups in 'location_id': 10\n\nConvergence Information:\nConverged: None\nTotal epochs: 3000\nFinal negative log-likelihood: 487.560577\nFixed Effects for Environmental Factors:\ntemperature    0.053341\nwind_speed    -0.096175\nis_weekend     0.575471\ndtype: float32\n\nAngler Random Effects (skill, top 5):\n   angler_id  Intercept\n26       A34   2.248726\n19       A28   1.892097\n2        A11   1.508491\n31       A39   1.416796\n40       A48   1.284273\n\nLocation Random Effects (quality, top 5):\n  location_id  Intercept\n4          L4   2.013306\n2          L2   1.112878\n6          L6   0.282911\n0          L1   0.092442\n9          L9  -0.050812\n\nPredicted fish counts for new trips:\nAngler A13 at L9 (temp=14.2°C, wind=12.1km/h, weekend=True): 2.32 fish\nAngler A46 at L7 (temp=10.0°C, wind=0.6km/h, weekend=True): 4.75 fish\nAngler A5 at L2 (temp=24.5°C, wind=11.0km/h, weekend=False): 15.51 fish\nAngler A8 at L7 (temp=16.0°C, wind=0.9km/h, weekend=False): 2.01 fish\nAngler A40 at L2 (temp=21.6°C, wind=3.0km/h, weekend=False): 14.79 fish\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate synthetic count data (e.g., number of fish caught)\n",
    "n_anglers = 50\n",
    "n_locations = 10\n",
    "n_observations = 200\n",
    "\n",
    "# Angler and location characteristics\n",
    "angler_skill = np.random.normal(0, 1, n_anglers)\n",
    "location_quality = np.random.normal(0, 1, n_locations)\n",
    "\n",
    "# Environmental factors\n",
    "temperature = np.random.uniform(10, 30, n_observations)\n",
    "wind_speed = np.random.uniform(0, 20, n_observations)\n",
    "is_weekend = np.random.choice([0, 1], size=n_observations, p=[0.7, 0.3])\n",
    "\n",
    "# Generate data\n",
    "data_rows = []\n",
    "for i in range(n_observations):\n",
    "    angler_id = np.random.randint(0, n_anglers)\n",
    "    location_id = np.random.randint(0, n_locations)\n",
    "    \n",
    "    # Expected count based on fixed and random effects\n",
    "    log_lambda = (\n",
    "        1.0 +  # baseline\n",
    "        0.05 * temperature[i] - \n",
    "        0.1 * wind_speed[i] + \n",
    "        0.5 * is_weekend[i] +\n",
    "        angler_skill[angler_id] +\n",
    "        location_quality[location_id]\n",
    "    )\n",
    "    \n",
    "    lambda_val = np.exp(log_lambda)\n",
    "    fish_count = np.random.poisson(lambda_val)\n",
    "    \n",
    "    data_rows.append({\n",
    "        'angler_id': f\"A{angler_id+1}\",\n",
    "        'location_id': f\"L{location_id+1}\",\n",
    "        'temperature': temperature[i],\n",
    "        'wind_speed': wind_speed[i],\n",
    "        'is_weekend': is_weekend[i],\n",
    "        'fish_count': fish_count\n",
    "    })\n",
    "\n",
    "fishing_data = pd.DataFrame(data_rows)\n",
    "\n",
    "# Fit a Poisson mixed model\n",
    "model = GLMM(\n",
    "    formula=\"fish_count ~ temperature + wind_speed + is_weekend + (1 | angler_id) + (1 | location_id)\",\n",
    "    data=fishing_data,\n",
    "    distribution='poisson',\n",
    "    link='log'\n",
    ")\n",
    "\n",
    "# Train with L2 regularization\n",
    "model.fit(lr=0.01, epochs=3000, verbose=True)\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Check fixed effects estimates \n",
    "print(\"Fixed Effects for Environmental Factors:\")\n",
    "fixed_effects = model.fixef[['temperature', 'wind_speed', 'is_weekend']]\n",
    "print(fixed_effects)\n",
    "\n",
    "# Check random effects for anglers\n",
    "print(\"\\nAngler Random Effects (skill, top 5):\")\n",
    "top_anglers = model.ranef['angler_id'].sort_values('Intercept', ascending=False).head(5)\n",
    "print(top_anglers)\n",
    "\n",
    "# Check random effects for locations\n",
    "print(\"\\nLocation Random Effects (quality, top 5):\")\n",
    "top_locations = model.ranef['location_id'].sort_values('Intercept', ascending=False).head(5)\n",
    "print(top_locations)\n",
    "\n",
    "# Predict fish counts for new fishing trips\n",
    "new_trips = pd.DataFrame({\n",
    "    'angler_id': np.random.choice(fishing_data['angler_id'].unique(), size=5),\n",
    "    'location_id': np.random.choice(fishing_data['location_id'].unique(), size=5),\n",
    "    'temperature': np.random.uniform(10, 30, 5),\n",
    "    'wind_speed': np.random.uniform(0, 20, 5),\n",
    "    'is_weekend': np.random.choice([0, 1], size=5)\n",
    "})\n",
    "\n",
    "predicted_counts = model.predict(new_data=new_trips)\n",
    "print(\"\\nPredicted fish counts for new trips:\")\n",
    "for i, (idx, trip) in enumerate(new_trips.iterrows()):\n",
    "    print(f\"Angler {trip['angler_id']} at {trip['location_id']} \"\n",
    "          f\"(temp={trip['temperature']:.1f}°C, wind={trip['wind_speed']:.1f}km/h, \"\n",
    "          f\"weekend={bool(trip['is_weekend'])}): {predicted_counts[i][0]:.2f} fish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7bfe130b-d155-4e34-8f74-347268029d2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Example 5: Gamma Model for Positive Continuous Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd8dbc83-916c-4f16-bded-cdd989b9272c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with automatic convergence detection...\nTolerance: 0.0001, Patience: 5, Check interval: 100\nEpoch 0: Negative Log-Likelihood = 815446.0625\nEpoch 500: Negative Log-Likelihood = 10625.6582\nEpoch 1000: Negative Log-Likelihood = 6429.8433\nEpoch 1500: Negative Log-Likelihood = 5361.6030\nEpoch 2000: Negative Log-Likelihood = 4970.9575\nEpoch 2500: Negative Log-Likelihood = 4803.7568\nEpoch 3000: Negative Log-Likelihood = 4711.9233\nEpoch 3500: Negative Log-Likelihood = 4642.3750\nEpoch 4000: Negative Log-Likelihood = 4565.6411\nEpoch 4500: Negative Log-Likelihood = 4435.5527\nEpoch 5000: Negative Log-Likelihood = 4145.5024\nEpoch 5500: Negative Log-Likelihood = 3890.0288\nEpoch 6000: Negative Log-Likelihood = 3682.9675\nEpoch 6500: Negative Log-Likelihood = 3493.4956\nEpoch 7000: Negative Log-Likelihood = 3314.7144\nEpoch 7500: Negative Log-Likelihood = 3144.8384\nEpoch 8000: Negative Log-Likelihood = 2982.5674\nEpoch 8500: Negative Log-Likelihood = 2828.7886\nEpoch 9000: Negative Log-Likelihood = 2687.0222\nEpoch 9500: Negative Log-Likelihood = 2556.5522\nEpoch 10000: Negative Log-Likelihood = 2461.1743\nEpoch 10500: Negative Log-Likelihood = 2387.3167\nEpoch 10800: Potential convergence detected (relative change: 0.000046)\nEpoch 11000: Negative Log-Likelihood = 2290.4670\nEpoch 11500: Negative Log-Likelihood = 2306.4478\nEpoch 12000: Negative Log-Likelihood = 2173.7603\nEpoch 12500: Negative Log-Likelihood = 2101.1887\nEpoch 13000: Negative Log-Likelihood = 2059.5796\nEpoch 13500: Negative Log-Likelihood = 2083.7937\nEpoch 14000: Negative Log-Likelihood = 2082.3596\nEpoch 14500: Negative Log-Likelihood = 1898.7493\nEpoch 15000: Negative Log-Likelihood = 1997.3281\nEpoch 15500: Negative Log-Likelihood = 1882.1238\nEpoch 16000: Negative Log-Likelihood = 1899.5115\nEpoch 16500: Negative Log-Likelihood = 1991.0266\nEpoch 17000: Negative Log-Likelihood = 1856.1218\nEpoch 17500: Negative Log-Likelihood = 1859.6440\nEpoch 18000: Negative Log-Likelihood = 1814.5359\nEpoch 18500: Negative Log-Likelihood = 1884.6460\nEpoch 19000: Negative Log-Likelihood = 1856.2690\nEpoch 19500: Negative Log-Likelihood = 1832.2473\nEpoch 19999: Negative Log-Likelihood = 1905.3562\nWarning: Reached maximum epochs (20000) without converging\nFinal negative log-likelihood: 1905.356201\nTraining status: Not converged\nTotal epochs run: 20000\nFixed Effects (beta):\n        Variable  Coefficient\n0      Intercept     4.564107\n1            age     0.011417\n2    vehicle_age     0.049208\n3  vehicle_value    -0.151597\n4  is_sports_car     0.434620\n\nRandom Effects for 'policyholder_id':\nRandom Effects Std Dev (sigma_b) per component:\n    Variable   Std Dev\n0  Intercept  0.000029\n\nRandom Effects for 'region_id':\nRandom Effects Std Dev (sigma_b) per component:\n    Variable   Std Dev\n0  Intercept  2.148187\n\nGamma shape parameter (phi): 1.2096\n\nModel Information:\nDistribution: gamma\nLink function: log\nNumber of observations: 500\nNumber of groups in 'policyholder_id': 252\nNumber of groups in 'region_id': 20\n\nConvergence Information:\nConverged: False\nTotal epochs: 20000\nFinal negative log-likelihood: 1905.356201\n\nFixed Effects (impact on mean claim amount):\nage              0.011417\nvehicle_age      0.049208\nvehicle_value   -0.151597\nis_sports_car    0.434620\ndtype: float32\n\nRegions with Highest Risk (top 5):\n   region_id  Intercept\n13        R3   2.907743\n9        R18   2.673731\n8        R17   2.577476\n10       R19   2.533242\n3        R12   2.455122\n\nPredicted claim amounts for new policies:\nPolicyholder P226 in region R1: $1615.37\nPolicyholder P117 in region R14: $1060.39\nPolicyholder P164 in region R17: $1514.50\nPolicyholder P271 in region R15: $1754.60\nPolicyholder P5 in region R4: $1770.88\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate synthetic insurance claim data\n",
    "n_policyholders = 300\n",
    "n_regions = 20\n",
    "n_observations = 500\n",
    "\n",
    "# Policyholder and region characteristics\n",
    "policyholder_risk = np.random.gamma(2, 0.5, n_policyholders)  # Shape, scale\n",
    "region_risk = np.random.gamma(2, 0.5, n_regions)\n",
    "\n",
    "# Create data rows\n",
    "data_rows = []\n",
    "for i in range(n_observations):\n",
    "    policyholder_id = np.random.randint(0, n_policyholders)\n",
    "    region_id = np.random.randint(0, n_regions)\n",
    "    \n",
    "    # Factors affecting claim amount\n",
    "    age = np.random.uniform(18, 80)\n",
    "    vehicle_age = np.random.uniform(0, 15)\n",
    "    vehicle_value = np.random.uniform(5000, 50000)\n",
    "    is_sports_car = np.random.choice([0, 1], p=[0.9, 0.1])\n",
    "    \n",
    "    # Expected mean claim amount (shape parameter for gamma)\n",
    "    log_mean = (\n",
    "        7.0 +  # baseline (around $1000)\n",
    "        0.01 * age +\n",
    "        0.05 * vehicle_age -\n",
    "        0.00001 * vehicle_value +\n",
    "        0.5 * is_sports_car +\n",
    "        np.log(policyholder_risk[policyholder_id]) +\n",
    "        np.log(region_risk[region_id])\n",
    "    )\n",
    "    \n",
    "    mean_claim = np.exp(log_mean)\n",
    "    shape = 2.0  # Fixed shape parameter for gamma\n",
    "    scale = mean_claim / shape\n",
    "    claim_amount = np.random.gamma(shape, scale)\n",
    "    \n",
    "    data_rows.append({\n",
    "        'policyholder_id': f\"P{policyholder_id+1}\",\n",
    "        'region_id': f\"R{region_id+1}\",\n",
    "        'age': age,\n",
    "        'vehicle_age': vehicle_age,\n",
    "        'vehicle_value': vehicle_value / 10000,  # Scale for numerical stability\n",
    "        'is_sports_car': is_sports_car,\n",
    "        'claim_amount': claim_amount\n",
    "    })\n",
    "\n",
    "claim_data = pd.DataFrame(data_rows)\n",
    "\n",
    "# Fit a Gamma mixed model\n",
    "model = GLMM(\n",
    "    formula=\"claim_amount ~ age + vehicle_age + vehicle_value + is_sports_car + (1 | policyholder_id) + (1 | region_id)\",\n",
    "    data=claim_data,\n",
    "    distribution='gamma',\n",
    "    link='log'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(lr=0.001, convergence=True, tol=1e-4, verbose=True)\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Examine model coefficients\n",
    "print(\"\\nFixed Effects (impact on mean claim amount):\")\n",
    "print(model.fixef[['age', 'vehicle_age', 'vehicle_value', 'is_sports_car']])\n",
    "\n",
    "# Check highest risk regions\n",
    "print(\"\\nRegions with Highest Risk (top 5):\")\n",
    "high_risk_regions = model.ranef['region_id'].sort_values('Intercept', ascending=False).head(5)\n",
    "print(high_risk_regions)\n",
    "\n",
    "# Predict claim amounts for new policies\n",
    "new_policies = pd.DataFrame({\n",
    "    'policyholder_id': np.random.choice(claim_data['policyholder_id'].unique(), size=5),\n",
    "    'region_id': np.random.choice(claim_data['region_id'].unique(), size=5),\n",
    "    'age': np.random.uniform(18, 80, 5),\n",
    "    'vehicle_age': np.random.uniform(0, 15, 5),\n",
    "    'vehicle_value': np.random.uniform(0.5, 5.0, 5),  # Already scaled\n",
    "    'is_sports_car': np.random.choice([0, 1], size=5, p=[0.9, 0.1])\n",
    "})\n",
    "\n",
    "predicted_claims = model.predict(new_data=new_policies)\n",
    "print(\"\\nPredicted claim amounts for new policies:\")\n",
    "for i, (idx, policy) in enumerate(new_policies.iterrows()):\n",
    "    print(f\"Policyholder {policy['policyholder_id']} in region {policy['region_id']}: \"\n",
    "          f\"${predicted_claims[i][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a707604a-4462-4765-8992-951449bbc7bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Example 6: Categorical Predictors and Regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0a54ed3-218e-48a7-ac66-482997342189",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Negative Log-Likelihood = 1835.9475\nEpoch 500: Negative Log-Likelihood = 59.0581\nEpoch 1000: Negative Log-Likelihood = 54.7174\nEpoch 1500: Negative Log-Likelihood = 50.6652\nEpoch 2000: Negative Log-Likelihood = 50.4187\nEpoch 2500: Negative Log-Likelihood = 50.4174\nEpoch 2999: Negative Log-Likelihood = 50.4174\nFinal negative log-likelihood: 50.417366\nFixed Effects (beta):\n                Variable  Coefficient\n0              Intercept     2.690488\n1                    age     0.009039\n2                 tenure     0.049134\n3  education_High School    -0.064921\n4       education_Master     0.141812\n5          education_PhD     0.233640\n6              role_Lead     0.593467\n7         role_Mid-level     0.165161\n8            role_Senior     0.417775\n\nRandom Effects for 'department_id':\nRandom Effects Std Dev (sigma_b) per component:\n    Variable   Std Dev\n0  Intercept  0.431042\n\nRandom Effects for 'manager_id':\nRandom Effects Std Dev (sigma_b) per component:\n    Variable   Std Dev\n0  Intercept  0.271097\n\nResidual Std Dev (sigma_y): 0.2992\n\nModel Information:\nDistribution: gaussian\nLink function: identity\nNumber of observations: 200\nNumber of groups in 'department_id': 8\nNumber of groups in 'manager_id': 20\n\nCategorical Variables:\n  - education: 4 categories\n  - role: 4 categories\n\nConvergence Information:\nConverged: None\nTotal epochs: 3000\nFinal negative log-likelihood: 50.417366\n\nFixed Effects for Education Levels:\neducation_High School   -0.064921\neducation_Master         0.141812\neducation_PhD            0.233640\ndtype: float32\n\nFixed Effects for Roles:\nrole_Lead         0.593467\nrole_Mid-level    0.165161\nrole_Senior       0.417775\ndtype: float32\n\nDepartment Random Effects:\n  department_id  Intercept\n2            D3   0.584376\n4            D5   0.368049\n3            D4   0.302251\n0            D1   0.211889\n6            D7   0.111338\n5            D6  -0.306221\n7            D8  -0.392212\n1            D2  -0.783053\n\nManager Random Effects (top and bottom 3):\nTop 3 managers:\n   manager_id  Intercept\n5         M14   0.713363\n13         M3   0.447973\n1         M10   0.245967\n\nBottom 3 managers:\n   manager_id  Intercept\n4         M13  -0.321113\n19         M9  -0.415507\n8         M17  -0.415574\n\nPredicted satisfaction scores for new employees:\nMid-level with Bachelor degree, age 62.2, tenure 6.3 years, in department D3 under manager M5: 4.47/5.0\nJunior with Bachelor degree, age 59.5, tenure 11.0 years, in department D5 under manager M16: 4.01/5.0\nLead with High School degree, age 29.4, tenure 0.8 years, in department D5 under manager M19: 3.71/5.0\nJunior with PhD degree, age 34.3, tenure 19.5 years, in department D1 under manager M11: 4.46/5.0\nLead with Bachelor degree, age 56.7, tenure 0.5 years, in department D3 under manager M19: 4.22/5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate synthetic employee satisfaction data\n",
    "n_employees = 200\n",
    "n_departments = 8\n",
    "n_managers = 20\n",
    "\n",
    "# Employee characteristics\n",
    "age = np.random.uniform(22, 65, n_employees)\n",
    "tenure = np.random.uniform(0, 20, n_employees)\n",
    "education = np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'], size=n_employees)\n",
    "role = np.random.choice(['Junior', 'Mid-level', 'Senior', 'Lead'], size=n_employees)\n",
    "\n",
    "# Department and manager random effects\n",
    "department_effect = np.random.normal(0, 0.5, n_departments)\n",
    "manager_effect = np.random.normal(0, 0.4, n_managers)\n",
    "\n",
    "# Generate department and manager assignments\n",
    "department_id = np.random.choice(range(n_departments), size=n_employees)\n",
    "manager_id = np.random.choice(range(n_managers), size=n_employees)\n",
    "\n",
    "# Generate satisfaction scores\n",
    "base_satisfaction = 3.0\n",
    "age_effect = 0.01 * (age - 40)  # Centered at 40\n",
    "tenure_effect = 0.05 * tenure\n",
    "education_effect = {\n",
    "    'High School': 0.0, \n",
    "    'Bachelor': 0.1, \n",
    "    'Master': 0.2, \n",
    "    'PhD': 0.3\n",
    "}\n",
    "role_effect = {\n",
    "    'Junior': -0.2, \n",
    "    'Mid-level': 0.0, \n",
    "    'Senior': 0.3, \n",
    "    'Lead': 0.5\n",
    "}\n",
    "\n",
    "# Calculate mean satisfaction\n",
    "satisfaction = np.zeros(n_employees)\n",
    "for i in range(n_employees):\n",
    "    satisfaction[i] = (\n",
    "        base_satisfaction +\n",
    "        age_effect[i] +\n",
    "        tenure_effect[i] +\n",
    "        education_effect[education[i]] +\n",
    "        role_effect[role[i]] +\n",
    "        department_effect[department_id[i]] +\n",
    "        manager_effect[manager_id[i]] +\n",
    "        np.random.normal(0, 0.3)  # Noise term\n",
    "    )\n",
    "\n",
    "# Clip to valid range\n",
    "satisfaction = np.clip(satisfaction, 1, 5)\n",
    "\n",
    "# Create dataframe\n",
    "employee_data = pd.DataFrame({\n",
    "    'employee_id': [f\"E{i+1}\" for i in range(n_employees)],\n",
    "    'age': age,\n",
    "    'tenure': tenure,\n",
    "    'education': education,\n",
    "    'role': role,\n",
    "    'department_id': [f\"D{i+1}\" for i in department_id],\n",
    "    'manager_id': [f\"M{i+1}\" for i in manager_id],\n",
    "    'satisfaction': satisfaction\n",
    "})\n",
    "\n",
    "# Fit the model with categorical predictors and L2 regularization\n",
    "model = GLMM(\n",
    "    formula=\"satisfaction ~ age + tenure + education + role + (1 | department_id) + (1 | manager_id)\",\n",
    "    data=employee_data,\n",
    "    distribution='gaussian',\n",
    "    link='identity',\n",
    "    regularization='L2',\n",
    "    reg_lambda=0.1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(lr=0.01, epochs=3000, verbose=True)\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Examine the effect of categorical variables\n",
    "print(\"\\nFixed Effects for Education Levels:\")\n",
    "education_effects = [col for col in model.fixef.index if 'education' in col]\n",
    "print(model.fixef[education_effects])\n",
    "\n",
    "print(\"\\nFixed Effects for Roles:\")\n",
    "role_effects = [col for col in model.fixef.index if 'role' in col]\n",
    "print(model.fixef[role_effects])\n",
    "\n",
    "# Check department effects\n",
    "print(\"\\nDepartment Random Effects:\")\n",
    "print(model.ranef['department_id'].sort_values('Intercept', ascending=False))\n",
    "\n",
    "# Manager effects\n",
    "print(\"\\nManager Random Effects (top and bottom 3):\")\n",
    "manager_effects = model.ranef['manager_id'].sort_values('Intercept', ascending=False)\n",
    "print(\"Top 3 managers:\")\n",
    "print(manager_effects.head(3))\n",
    "print(\"\\nBottom 3 managers:\")\n",
    "print(manager_effects.tail(3))\n",
    "\n",
    "# Predict satisfaction for new employees\n",
    "new_employees = pd.DataFrame({\n",
    "    'age': np.random.uniform(22, 65, 5),\n",
    "    'tenure': np.random.uniform(0, 20, 5),\n",
    "    'education': np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'], size=5),\n",
    "    'role': np.random.choice(['Junior', 'Mid-level', 'Senior', 'Lead'], size=5),\n",
    "    'department_id': np.random.choice(employee_data['department_id'].unique(), size=5),\n",
    "    'manager_id': np.random.choice(employee_data['manager_id'].unique(), size=5)\n",
    "})\n",
    "\n",
    "predicted_satisfaction = model.predict(new_data=new_employees)\n",
    "print(\"\\nPredicted satisfaction scores for new employees:\")\n",
    "for i, (idx, emp) in enumerate(new_employees.iterrows()):\n",
    "    print(f\"{emp['role']} with {emp['education']} degree, age {emp['age']:.1f}, \"\n",
    "          f\"tenure {emp['tenure']:.1f} years, in department {emp['department_id']} \"\n",
    "          f\"under manager {emp['manager_id']}: {predicted_satisfaction[i][0]:.2f}/5.0\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Classe",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}